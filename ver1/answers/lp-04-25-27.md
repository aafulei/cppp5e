18/02/03 = Sat

**Exercise 4.25:** What is the value of `~'q' << 6` on a machine with 32-bit `int`s and 8 bit `char`s, that uses Latin-1 character set in which `'q'` has the bit pattern `01110001`?

**Answer:** 

First, `01110001` is promoted to `00000000 00000000 00000000 01110001`.

Then, `~'q'` is evaluated as `11111111 11111111 11111111 10001110`.

In the end, `~'q' << 6` is `11111111 11111111 11100011 10000000`, or `-7296` in decimal.

How do we know it's `-7296` in decimal?

In order to write in octal, we write it as`011 111 111 111 111 111 110 001 110 000 000`.

That's `37777761600` in octal.

With `cout << 037777761600 << endl;` we know that's `-7296`.

**Exercise 4.26:** In our grading example in this section, what would happen if we used `unsigned int` as the type for `quiz1`?

```c++
unsigned long quiz1 = 0; // we'll use this value as a collection of bits
1UL << 27 // generate a value with only bit number 27 set
quiz1 |= 1UL << 27; // indicate student number 27 passed
quiz1 &= ~(1UL << 27); // student number 27 failed
bool status = quiz1 & (1UL << 27); // how did student number 27 do?
```

**Answer:**  Suppose `quiz1` is an `unsigned int`. `quiz1 | 1UL << 27` would return an `unsigned long`. Assigning this `unsigned long` to an `unsigned int` could be undefined, if the `unsigned int` has only 16 bits whereas the `unsigned long` has 32 bits.

**Exercise 4.27:** What is the result of each of these expressions?

```c++
unsigned long ul1 = 3, ul2 = 7;
```

(a) `ul1 & ul2`

(b) `ul1 | ul2`

(c) `ul1 && ul2`

(d) `ul1 || ul2`

**Answer:** For the rightmost 8 bits:

(a) `0000 0011 & 0000 0111` returns `0000 0011`, which is 3.

(b) `0000 0011 | 0000 0111` returns `0000 0111`, which is 7.

(c) `3 && 7` returns `true`, or `1` as integral.

(d) `3 || 7` returns `true`, or `1` as integral.